{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://cdni.iconscout.com/illustration/premium/thumb/stock-market-growth-5788121-4849094.png?f=webp\" alt=\"Nobel Prize\" width=\"350\" align=\"left\" hspace=\"10\">\n",
    "    <h1>Tehran Stock Exchange</h1>\n",
    "</div>\n",
    "\n",
    "ðŸš€temptemptemptemptemptemptemptemptemptemptemptemptemptemptemptemp!<br> \n",
    "temptemptemptemptemptemptemptemptemptemptemptemptemptemptemptemp,\n",
    "temptemptemptemptemptemptemptemptemptemptemptemptemptemptemptemp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import jdatetime\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STAGE_DIR_PATH = \"./stage\"\n",
    "DATE_LAKE_DIR_PATH = \"./datalake\"\n",
    "\n",
    "# 1. Create Folder\n",
    "def create_folders():\n",
    "    # Stage Folder\n",
    "    data_dir = pathlib.Path(f'./stage')\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Data Lake Foler\n",
    "    data_dir = pathlib.Path(f'./datalake')\n",
    "    data_dir.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "# 2. Create single URL \n",
    "def url_genrator(jalali_date):\n",
    "    excel_url = f\"http://members.tsetmc.com/tsev2/excel/MarketWatchPlus.aspx?d={jalali_date}\"\n",
    "    return excel_url\n",
    "\n",
    "# 3. Download From URL\n",
    "def url_downloader(excel_url, save_path):\n",
    "    \n",
    "    response = requests.get(excel_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        logger.info(f\"Download successful. File saved at: {save_path}\")\n",
    "    else:\n",
    "        logger.info(f\"Failed to download. Status code: {response.status_code}\")\n",
    "        \n",
    "# 4. Change Format to CSV\n",
    "def change_format_to_csv(excel_path, save_path):\n",
    "    \n",
    "    df = pd.read_excel(excel_path, skiprows=2)\n",
    "    \n",
    "    if df.shape != 0:\n",
    "        df.to_csv(save_path,encoding=\"utf-8\", index=False)\n",
    "        logger.info(f\"format changed successfully!\")\n",
    "    \n",
    "# 5. Main \n",
    "def download_tehran_stock_exchange_files(start_date, end_date, delete_excel=True):\n",
    "    \n",
    "    start_date = jdatetime.datetime.strptime(start_date, format=\"%Y-%m-%d\").date()\n",
    "    end_date = jdatetime.datetime.strptime(end_date, format=\"%Y-%m-%d\").date()\n",
    "    \n",
    "    interval = (end_date - start_date).days\n",
    "    for i in tqdm(range(0,interval+1)):\n",
    "        jalali_date = start_date + jdatetime.timedelta(days=i)\n",
    "        \n",
    "        # Skip Weekends\n",
    "        if jalali_date.weekday() not in (5,6):\n",
    "            url = url_genrator(jalali_date=jalali_date.__str__())\n",
    "            url_downloader(excel_url=url, save_path=f\"./datalake/tehran_stock_exchange_{jalali_date.__str__()}.xlsx\")\n",
    "    \n",
    "            change_format_to_csv(f\"./datalake/tehran_stock_exchange_{jalali_date.__str__()}.xlsx\",f\"./datalake/tehran_stock_exchange_{jalali_date.__str__()}.csv\")\n",
    "    \n",
    "    if delete_excel:\n",
    "        excel_file_path = pathlib.Path(f\"./datalake/tehran_stock_exchange_{jalali_date.__str__()}.xlsx\")\n",
    "\n",
    "        # Check if the file exists before attempting to delete\n",
    "        if excel_file_path.exists():\n",
    "            try:\n",
    "                # Delete the file\n",
    "                excel_file_path.unlink()\n",
    "                print(f\"{excel_file_path} has been deleted successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {excel_file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"The file {excel_file_path} does not exist.\")\n",
    "            \n",
    "\n",
    "def download_tehran_stock_exchange_files(start_date, end_date):\n",
    "    \n",
    "    #create folder\n",
    "    data_dir = pathlib.Path(f'./stage')\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    start_date = jdatetime.datetime.strptime(start_date, format=\"%Y-%m-%d\").date()\n",
    "    end_date = jdatetime.datetime.strptime(end_date, format=\"%Y-%m-%d\").date()\n",
    "    \n",
    "    interval = (end_date - start_date).days\n",
    "    for i in tqdm(range(0,interval+1)):\n",
    "        jalali_date = start_date + jdatetime.timedelta(days=i)\n",
    "        \n",
    "        # Skip Weekends\n",
    "        if jalali_date.weekday() not in (5,6):\n",
    "            url = url_genrator(jalali_date=jalali_date.__str__())\n",
    "            url_downloader(excel_url=url, save_path=f\"./stage/tehran_stock_exchange_{jalali_date.__str__()}.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_tehran_stock_exchange_files(\"1402-9-1\", \"1402-9-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-s','--start_date',help='Start Date Tehran Exchange Market')\n",
    "parser.add_argument('-e','--end_date',help='End Date Tehran Exchange Market')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "download_tehran_stock_exchange_files(args.start_date, args.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path('.').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_list = pathlib.Path('/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-02.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-02.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-03.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-03.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-04.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-04.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-05.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-05.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-06.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-06.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-09.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-09.csv\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage/tehran_stock_exchange_1402-10-10.xlsx\n",
      "/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/datalake/tehran_stock_exchange_1402-10-10.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path_list = pathlib.Path('/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src/stage').resolve()\n",
    "new_directory = 'datalake'\n",
    "for file_path in file_path_list.glob('*'):\n",
    "    excel_file_path = file_path\n",
    "    print(excel_file_path)\n",
    "    print(file_path_list.parent / new_directory / (file_path.stem + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/Users/user/OneDrive/Desktop/data-engineer-roadmap/projects/Filager/src')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_list.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
